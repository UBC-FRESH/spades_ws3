{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype implementation of anticipation function interface\n",
    "\n",
    "This notebook implements a prototype interface for modelling _anticipation functions_ (AF) of non-timber values within the optimization models solved by `ws3`.\n",
    "\n",
    "We will test usefulness of the design by implementing both bird and caribou demographic population model AFs. We will implement these AFs as linear constraints in the optimization model.\n",
    "\n",
    "The proposed implementation automates the process of formulating the new constraints and injecting them into the optimization model. The user interface with the AF is basically to provide a string _expression_ that can be resolved by the `ws3` expression parser. This expression may refer to one or more yield curves or constants that are already built into the model. In some cases, users may need to add yield curves to an existing model for their expressions to parse correctly (e.g., we may need to add biomass volume yield curves for the bird model, which may in turn convert merchantable volume yield curves). \n",
    "\n",
    "The `spadesws3` module already includes a `_gen_scen_base` high-level function that automates the process of generating a (base scenario) optimization problem in a way that is compatible with the `ws3.forest.ForestModel.add_problem` method (which in turn automates the process of generating a valid Model I optimization problem and interfacing with an external solver via the lower-level optimization interface built into the `ws3.optimize` submodule). We will attempt to extend this high-level interface to include an AF component. \n",
    "\n",
    "Assuming that any missing yield curves have already been added to the model, adding an AF will basically involve\n",
    "* defining a `cmp_c_cXXX` function functions to compile appropriate  coefficients for the constraint rows of the optimization problem matrix (given a `ForestModel` instance, a path from a DevelopmentType state tree, a string expression to evaluate, and a mask string), which ;\n",
    "* adding items to `coeff_funcs` and `cgen_data` dicts inside the `_gen_scen_*` function (using matching keys). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/shared/project/ria/modules/spades_ws3/python\n",
      "['/mnt/shared/project/ria/modules/spades_ws3/python', '/opt/tljh/user/lib/python36.zip', '/opt/tljh/user/lib/python3.6', '/opt/tljh/user/lib/python3.6/lib-dynload', '', '/opt/tljh/user/lib/python3.6/site-packages', '/mnt/shared/project/ws3', '/opt/tljh/user/lib/python3.6/site-packages/IPython/extensions', '/mnt/home/jupyter-gparadis/.ipython']\n"
     ]
    }
   ],
   "source": [
    "# emulate the Python environement we use in the spades_ws3 module\n",
    "dat_path = '../../../input'\n",
    "from spadesws3 import read_basenames, schedule_harvest_areacontrol\n",
    "\n",
    "#basenames = read_basenames(dat_path+'/basenames.txt')\n",
    "basenames = ['tsa08', 'tsa16', 'tsa24', 'tsa40', 'tsa41']\n",
    "#basenames = ['tsa40']\n",
    "%run -i spadesws3_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying ../../../input/tif/tsa08/inventory_init.tif ../../../input/tif/tsa08/inventory_2015.tif\n",
      "copying ../../../input/tif/tsa16/inventory_init.tif ../../../input/tif/tsa16/inventory_2015.tif\n",
      "copying ../../../input/tif/tsa24/inventory_init.tif ../../../input/tif/tsa24/inventory_2015.tif\n",
      "copying ../../../input/tif/tsa40/inventory_init.tif ../../../input/tif/tsa40/inventory_2015.tif\n",
      "copying ../../../input/tif/tsa41/inventory_init.tif ../../../input/tif/tsa41/inventory_2015.tif\n",
      "bootstrap_areas tsa08 2015 6.25 7644875.0\n",
      "bootstrap_areas tsa16 2015 6.25 4780950.0\n",
      "bootstrap_areas tsa24 2015 6.25 6752206.25\n",
      "bootstrap_areas tsa40 2015 6.25 4195350.0\n",
      "bootstrap_areas tsa41 2015 6.25 2160268.75\n"
     ]
    }
   ],
   "source": [
    "# instantiate a new ws3.forest.ForestModel instance using the bootstrap function defined in spadesws3_params.py\n",
    "fm = bootstrap_forestmodel_kwargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate_harvest(fm, basenames, 2015, mode='optimize')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on caribou demographic model and its AF\n",
    "\n",
    "Now that we have handle to a known-working `ForestModel` instance that can solve the built-in base scenario optimization problem on one management unit (TSA 40, in north-eastern BC), we can work on integrating a caribou demographic AF.\n",
    "\n",
    "The caribou demographic AF is a _simplified version_ of a more complex caribou demographic model, which includes some spatially-explicit components that cannot easily be expressed in the context of an aspatial area-based optimization model (such as the one we solve here using `ws3`). \n",
    "\n",
    "The full caribou model itself is relatively simple, conceptually: we must keep _area affected by anthropogenic disturances_ below 40% of total forest area, where an area is considered affected by anthropogenic disturbances if it is located within 500 meters of an anthropogenic disturbance that occurred less than 40 years ago (including harvest blocks, roads, mines, seismic lines, etc.). \n",
    "\n",
    "We cannot account for any disturbances related to the mining industry or roads in `ws3`, so we will simply ignore those in our AF and only condider area disturbed by harvesting. We also cannot easily account for the 500 meter buffer around harvested areas in the optimization model (although we _should_ be able to estimate the buffered area in a post hoc analysis of the raster output of the SDA function (e.g., using the spatial analysis functions in the `rasterio` package).\n",
    "\n",
    "We _can_ however estimate the worst-case expansion factors based a geometric analysis, and then scale that worst-case down with a linear scaling factor that, if correctly calibrated for a given landscape, should result in a reasonably good approximation that we can use in an AF in the optimization model. We will base the prototype AF on this design.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the caribou AF\n",
    "\n",
    "As detailed in the previous section, we need to be able to track total _inventory_ area that is less than a given threshold age (40 years, in this example) over time (assuming this is a multi-period problem). The `ForestModel` class includes a flexible `inventory` method that is already set up to filter by age class, so this should be pretty simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying ../../../input/tif/tsa40/inventory_init.tif ../../../input/tif/tsa40/inventory_2015.tif\n",
      "bootstrap_areas tsa40 2015 6.25 4195350.0\n"
     ]
    }
   ],
   "source": [
    "horizon = 10\n",
    "fm = bootstrap_forestmodel_kwargs()\n",
    "fm.set_horizon(horizon)\n",
    "fm.grow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18343.75"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inventory of age class 40, period 1\n",
    "fm.inventory(1, age=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211837.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum of inventory for age classes up to and including 40, period 1\n",
    "sum(fm.inventory(1, age=age) for age in range(41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 211837.5,\n",
       " 2: 193493.75,\n",
       " 3: 187937.5,\n",
       " 4: 184887.5,\n",
       " 5: 182468.75,\n",
       " 6: 178181.25,\n",
       " 7: 166475.0,\n",
       " 8: 157175.0,\n",
       " 9: 151806.25,\n",
       " 10: 149375.0}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now loop through all periods\n",
    "{t:sum(fm.inventory(t, age=age) for age in range(1, 41)) for t in fm.periods}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can roll something like the above code into a function that is compatible with the format required for inclusion in the `coeff_funcs` argument of the `ForestModel.add_problem` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_c_cinv(fm, path, expr, ages=None, mask=None):\n",
    "    ages = fm.ages if not ages else ages \n",
    "    result = {t:sum(fm.inventory(t, age=age) for age in ages) for t in fm.periods}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.0, 2: 0.0}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr = '1.'\n",
    "ages = range(41)\n",
    "mask = '? ? ? ?'\n",
    "cmp_c_cinv(fm, expr, ages, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we copy the `gen_scen` functions from `spadesws3` and modify them a bit to include the caribou AF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spadesws3 import cmp_c_z, cmp_c_cflw, cmp_c_caa\n",
    "\n",
    "def _gen_scen_boo(fm, basenames, name='boo', util=0.85, param_funcs=None, harvest_acode='harvest',  \n",
    "                  tvy_name='totvol', toffset=0, obj_mode='max_hvol', target_path='./input/targets.csv',\n",
    "                  max_tp=2074, cacut=None, mask=None, boo_ages=range(1, 41), boo_dthresh=0.40):\n",
    "    from functools import partial\n",
    "    acodes = ['null', harvest_acode]  \n",
    "    vexpr = '%s * %0.2f' % (tvy_name, util)\n",
    "    if obj_mode == 'max_hvol':\n",
    "        sense = ws3.opt.SENSE_MAXIMIZE \n",
    "        zexpr = vexpr\n",
    "    elif obj_mode == 'min_harea':\n",
    "        sense = ws3.opt.SENSE_MINIMIZE \n",
    "        zexpr = '1.'\n",
    "    else:\n",
    "        raise ValueError('Invalid obj_mode: %s' % obj_mode)\n",
    "    if not param_funcs:\n",
    "        df_targets = pd.read_csv(target_path).set_index(['tsa', 'year'])\n",
    "        param_funcs = {}\n",
    "        param_funcs['cvcut'] = lambda bn, t: float(df_targets.loc[bn, t]['vcut']) if t <= max_tp else float(df_targets.loc[bn, max_tp]['vcut'])\n",
    "        param_funcs['cabrn'] = lambda bn, t: float(df_targets.loc[bn, t]['abrn']) if t <= max_tp else float(df_targets.loc[bn, max_tp]['abrn'])\n",
    "        # BOO ###\n",
    "        param_funcs['caboo'] = lambda bn: fm.inventory(0, mask='%s ? ? ?' % bn) * boo_dthresh\n",
    "        #########\n",
    "        param_funcs['cflw_acut_e'] = lambda bn, t: df_targets.loc[bn, t]['cflw_acut_e'] if t <= max_tp else df_targets.loc[bn, max_tp]['cflw_acut_e']\n",
    "        param_funcs['cgen_vcut_e'] = lambda bn, t: df_targets.loc[bn, t]['cgen_vcut_e'] if t <= max_tp else df_targets.loc[bn, max_tp]['cgen_vcut_e']\n",
    "        param_funcs['cgen_acut_e'] = lambda bn, t: df_targets.loc[bn, t]['cgen_vcut_e'] if t <= max_tp else df_targets.loc[bn, max_tp]['cgen_vcut_e']\n",
    "        param_funcs['cgen_abrn_e'] = lambda bn, t: df_targets.loc[bn, t]['cgen_abrn_e'] if t <= max_tp else df_targets.loc[bn, max_tp]['cgen_abrn_e']\n",
    "    coeff_funcs = {'z':partial(cmp_c_z, expr=zexpr)}\n",
    "    coeff_funcs.update({'cacut_%s' % bn:partial(cmp_c_caa, expr='1.', acodes=[harvest_acode], mask=(bn, '?', '?', '?')) for bn in basenames})\n",
    "    coeff_funcs.update({'cvcut_%s' % bn:partial(cmp_c_caa, expr=vexpr, acodes=[harvest_acode], mask=(bn, '?', '?', '?')) for bn in basenames})\n",
    "    # BOO ###\n",
    "    coeff_funcs.update({'caboo_%s' % bn:partial(cmp_c_cinv, expr='1.', ages=boo_ages, mask=(bn, '?', '?', '?')) for bn in basenames})\n",
    "    #########\n",
    "    T = fm.periods\n",
    "    cflw_e, cgen_data = {}, {}\n",
    "    for bn in basenames:\n",
    "        cgen_data.update({'cvcut_%s' % bn:{'lb':{t:param_funcs['cvcut'](bn, fm.base_year+(t-1)*fm.period_length+toffset) *\n",
    "                                                   (1. - param_funcs['cgen_vcut_e'](bn, fm.base_year+(t-1)*fm.period_length+toffset)) for t in T}, \n",
    "                                         'ub':{t:param_funcs['cvcut'](bn, fm.base_year+(t-1)*fm.period_length+toffset) for t in T}}})\n",
    "        # BOO ###\n",
    "        cgen_data.update({'caboo_%s' % bn:{'lb':{t:0. for t in T}, 'ub':{t:param_funcs['caboo'](bn) for t in T}}})\n",
    "        #########\n",
    "        if cacut:\n",
    "            cgen_data.update({'cacut_%s' % bn:{'lb':{t:param_funcs['cacut'](bn, fm.base_year+(t-1)*fm.period_length)*\n",
    "                                                       (1. - param_funcs['cgen_acut_e'](bn, fm.base_year+(t-1)*fm.period_length)) for t in T}, \n",
    "                                             'ub':{t:param_funcs['cacut'](bn, fm.base_year+(t-1)*fm.period_length) for t in T}}})\n",
    "    fm._tmp = {}\n",
    "    fm._tmp['param_funcs'] = param_funcs\n",
    "    fm._tmp['cgen_data'] = cgen_data\n",
    "    return fm.add_problem(name, coeff_funcs, cflw_e, cgen_data=cgen_data, acodes=acodes, sense=sense, mask=mask)\n",
    "\n",
    "\n",
    "def gen_scen(fm, basenames, name, util, param_funcs, toffset=0, obj_mode='max_hvol', cacut=None, mask=None, target_path='./input/targets.csv', **kwargs):\n",
    "    dsp = {'boo':_gen_scen_boo}\n",
    "    return dsp[name](fm, basenames, name, util, param_funcs=param_funcs, toffset=toffset, obj_mode=obj_mode, cacut=cacut, mask=mask, target_path=target_path, **kwargs)\n",
    "\n",
    "\n",
    "def schedule_harvest_optimize(fm, basenames, scenario_name='base', util=0.85, param_funcs=None, \n",
    "                              target_path='./input/targets.csv', obj_mode='min_harea', mask=None, **kwargs):\n",
    "    import gurobipy as grb\n",
    "    p = gen_scen(fm, basenames, scenario_name, util, param_funcs=param_funcs, toffset=0, obj_mode=obj_mode, mask=mask, target_path=target_path, **kwargs)\n",
    "    m = p.solve()\n",
    "    if m.status != grb.GRB.OPTIMAL:\n",
    "        print('Model not optimal.')\n",
    "        return None\n",
    "    sch = fm.compile_schedule(p)\n",
    "    fm.reset_actions()\n",
    "    fm.initialize_areas()\n",
    "    fm.apply_schedule(sch, \n",
    "                      force_integral_area=True, \n",
    "                      override_operability=True,\n",
    "                      fuzzy_age=True,\n",
    "                      recourse_enabled=True,\n",
    "                      verbose=False,\n",
    "                      compile_c_ycomps=True)\n",
    "    return sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copying ../../../input/tif/tsa40/inventory_init.tif ../../../input/tif/tsa40/inventory_2015.tif\n",
      "bootstrap_areas tsa40 2015 6.25 4195350.0\n"
     ]
    }
   ],
   "source": [
    "fm = bootstrap_forestmodel_kwargs()\n",
    "fm.dtypes = dict(list(fm.dtypes.items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.0.2 build v9.0.2rc0 (linux64)\n",
      "Optimize a model with 429 rows, 659 columns and 3771 nonzeros\n",
      "Model fingerprint: 0x0445b01c\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+05]\n",
      "  Objective range  [6e+00, 6e+03]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+06]\n",
      "Presolve removed 304 rows and 302 columns\n",
      "Presolve time: 0.01s\n",
      "\n",
      "Solved in 0 iterations and 0.01 seconds\n",
      "Infeasible model\n",
      "foo\n",
      "ws3.opt._solve_gurobi: Model infeasible, enabling feasRelaxS mode.\n",
      "Gurobi Optimizer version 9.0.2 build v9.0.2rc0 (linux64)\n",
      "Optimize a model with 429 rows, 1509 columns and 4621 nonzeros\n",
      "Model fingerprint: 0x32a5728b\n",
      "Model has 850 quadratic objective terms\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 6e+05]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  QObjective range [2e+00, 2e+00]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [1e+00, 1e+06]\n",
      "Presolve removed 2 rows and 2 columns\n",
      "Presolve time: 0.01s\n",
      "Presolved: 427 rows, 1507 columns, 3301 nonzeros\n",
      "Presolved model has 848 quadratic objective terms\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 1.329e+03\n",
      " Factor NZ  : 2.234e+03 (roughly 1 MByte of memory)\n",
      " Factor Ops : 2.182e+04 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   2.12000099e+08 -2.12000099e+08  4.36e+05 0.00e+00  1.00e+06     0s\n",
      "   1   8.21130008e+07 -8.58595010e+07  4.47e+04 0.00e+00  1.75e+05     0s\n",
      "   2   1.34209830e+07 -1.69806023e+07  9.23e+02 0.00e+00  2.11e+04     0s\n",
      "   3   2.08591578e+06 -2.65827806e+06  1.28e+01 0.00e+00  3.14e+03     0s\n",
      "   4   2.99919995e+05 -3.25686379e+05  6.07e-09 0.00e+00  4.13e+02     0s\n",
      "   5   4.35176171e+04 -4.69957892e+04  9.15e-12 0.00e+00  5.98e+01     0s\n",
      "   6   6.47018698e+03 -6.67744160e+03  4.53e-13 2.66e-15  8.69e+00     0s\n",
      "   7   1.13820976e+03 -8.43121723e+02  4.44e-15 1.11e-15  1.31e+00     0s\n",
      "   8   3.51136898e+02  9.76168315e+01  1.13e-14 5.55e-16  1.68e-01     0s\n",
      "   9   2.45163971e+02  2.31415265e+02  1.53e-14 3.61e-16  9.09e-03     0s\n",
      "  10   2.39965244e+02  2.38557833e+02  3.24e-14 1.77e-16  9.30e-04     0s\n",
      "  11   2.39456426e+02  2.39232224e+02  2.22e-14 2.10e-16  1.48e-04     0s\n",
      "  12   2.39377052e+02  2.39351221e+02  2.49e-14 2.22e-16  1.71e-05     0s\n",
      "  13   2.39367699e+02  2.39364148e+02  7.33e-14 2.66e-16  2.35e-06     0s\n",
      "  14   2.39366373e+02  2.39365911e+02  4.15e-14 2.09e-16  3.05e-07     0s\n",
      "  15   2.39366180e+02  2.39366163e+02  3.06e-14 1.94e-16  1.13e-08     0s\n",
      "  16   2.39366173e+02  2.39366172e+02  2.89e-15 2.48e-16  4.79e-10     0s\n",
      "\n",
      "Barrier solved model in 16 iterations and 0.02 seconds\n",
      "Optimal objective 2.39366173e+02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sch = schedule_harvest_optimize(fm, basenames, scenario_name='boo', target_path=target_path, boo_dthresh=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
